# vLLM QAç³»ç»Ÿ - å¿«é€Ÿä½¿ç”¨æŒ‡å—

## ğŸš€ ä¸€åˆ†é’Ÿå¿«é€Ÿå¯åŠ¨

### 1. å®‰è£…ä¾èµ–
```bash
cd new_qa
pip install -r requirements.txt
```

### 2. å¯åŠ¨ç³»ç»Ÿ
```bash
# æ–¹å¼1: ä½¿ç”¨å¿«é€Ÿå¯åŠ¨è„šæœ¬
./quick_start.sh

# æ–¹å¼2: æ‰‹åŠ¨å¯åŠ¨
# ç»ˆç«¯1: å¯åŠ¨vLLMæœåŠ¡å™¨
python start_vllm_server.py --model-path /your/model/path

# ç»ˆç«¯2: è¿è¡ŒQAç”Ÿæˆ
python run_semiconductor_qa.py --input-dir data/texts --output-dir data/qa_results --config config_vllm_http.json
```

## ğŸ“ ç›®å½•ç»“æ„
```
new_qa/
â”œâ”€â”€ start_vllm_server.py      # vLLMæœåŠ¡å™¨å¯åŠ¨å™¨
â”œâ”€â”€ run_semiconductor_qa.py   # ä¸»ç¨‹åº
â”œâ”€â”€ config_vllm_http.json     # vLLMé…ç½®
â”œâ”€â”€ quick_start.sh            # å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ texts/                # è¾“å…¥æ–‡æœ¬
â”‚   â””â”€â”€ qa_results/           # è¾“å‡ºç»“æœ
â””â”€â”€ requirements.txt          # ä¾èµ–åˆ—è¡¨
```

## âš™ï¸ æ ¸å¿ƒé…ç½®

### æ¨¡å‹è·¯å¾„é…ç½®
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export MODEL_PATH=/mnt/workspace/models/Qwen/QwQ-32B/

# æˆ–ç›´æ¥åœ¨å‘½ä»¤ä¸­æŒ‡å®š
python start_vllm_server.py --model-path /your/model/path
```

### æœåŠ¡å™¨é…ç½®
- é»˜è®¤ç«¯å£: 8000
- GPUå†…å­˜åˆ©ç”¨ç‡: 0.95
- å¼ é‡å¹¶è¡Œå¤§å°: 1

## ğŸ“ ä½¿ç”¨æµç¨‹

1. **å‡†å¤‡æ•°æ®**: å°†æ–‡æœ¬æ–‡ä»¶æ”¾å…¥ `data/texts/`
2. **å¯åŠ¨æœåŠ¡**: è¿è¡ŒvLLMæœåŠ¡å™¨
3. **ç”ŸæˆQA**: è¿è¡ŒQAç”Ÿæˆç¨‹åº
4. **æŸ¥çœ‹ç»“æœ**: æ£€æŸ¥ `data/qa_results/` ä¸­çš„è¾“å‡º

## ğŸ”§ å¸¸è§é—®é¢˜

**Q: vLLMå¯åŠ¨å¤±è´¥ï¼Ÿ**
A: æ£€æŸ¥GPUå†…å­˜ã€æ¨¡å‹è·¯å¾„ã€CUDAç‰ˆæœ¬

**Q: è¿æ¥è¶…æ—¶ï¼Ÿ**
A: ç¡®è®¤vLLMæœåŠ¡å™¨å·²å¯åŠ¨ï¼Œæ£€æŸ¥ç«¯å£å ç”¨

**Q: å†…å­˜ä¸è¶³ï¼Ÿ**
A: é™ä½gpu-memory-utilizationå‚æ•°

## ğŸ“ è·å–å¸®åŠ©

æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: `README.md`
è¿è¡Œå¸®åŠ©: `python start_vllm_server.py --help`